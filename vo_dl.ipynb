{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 11311414,
          "sourceType": "datasetVersion",
          "datasetId": 6945102
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use GPU 0 (change to \"1\" for second GPU, etc.)\n",
        "\n",
        "# Verify TensorFlow is using GPU\n",
        "print(\"✅ Available GPUs:\", tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T10:02:27.225770Z",
          "iopub.execute_input": "2025-04-15T10:02:27.226148Z",
          "iopub.status.idle": "2025-04-15T10:02:33.681042Z",
          "shell.execute_reply.started": "2025-04-15T10:02:27.226118Z",
          "shell.execute_reply": "2025-04-15T10:02:33.680004Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPMgsSq1b75b",
        "outputId": "2344efc1-eb4c-452a-d365-fb92ba3e748a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Available GPUs: []\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viBiepFWcsTx",
        "outputId": "298c7aff-7f6b-49ae-b761-91037ba9f87e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the zip file and the extraction directory\n",
        "zip_path = \"/content/drive/MyDrive/Virtual Operator/Dataset.zip\"\n",
        "extracted_dir = \"/content/sample_data\" # Directory to extract to\n",
        "\n",
        "# Extract the dataset if it hasn't been extracted already\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extracted_dir)\n",
        "\n",
        "\"\"\"\n",
        "source_dir = \"/kaggle/input/virtual-operator-proj-2025/Dataset\"  # Your read-only dataset\n",
        "dest_dir = \"/kaggle/working/Dataset\"  # Writable directory\n",
        "\n",
        "if not os.path.exists(dest_dir):\n",
        "    shutil.copytree(source_dir, dest_dir)\n",
        "    print(\"✅ Dataset copied to writable directory.\")\n",
        "else:\n",
        "    print(\"⚠️ Dataset already copied.\")\n",
        "\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T10:02:33.682525Z",
          "iopub.execute_input": "2025-04-15T10:02:33.683151Z",
          "iopub.status.idle": "2025-04-15T10:02:33.687799Z",
          "shell.execute_reply.started": "2025-04-15T10:02:33.683124Z",
          "shell.execute_reply": "2025-04-15T10:02:33.686884Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "TXCq3IChb75e",
        "outputId": "febdcc92-f0cd-4073-ceea-35d784b36a85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nsource_dir = \"/kaggle/input/virtual-operator-proj-2025/Dataset\"  # Your read-only dataset\\ndest_dir = \"/kaggle/working/Dataset\"  # Writable directory\\n\\nif not os.path.exists(dest_dir):\\n    shutil.copytree(source_dir, dest_dir)\\n    print(\"✅ Dataset copied to writable directory.\")\\nelse:\\n    print(\"⚠️ Dataset already copied.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = \"/content/sample_data/Dataset\"\n",
        "\n",
        "for root, _, files in os.walk(dataset_dir):\n",
        "    for file in files:\n",
        "        file_path = os.path.join(root, file)\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                img.verify()  # Verify if image is valid\n",
        "        except (IOError, SyntaxError):\n",
        "            print(f\"⚠️ Corrupt file detected and removed: {file_path}\")\n",
        "            os.remove(file_path)  # Delete corrupt file"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T10:02:33.689600Z",
          "iopub.execute_input": "2025-04-15T10:02:33.689897Z",
          "iopub.status.idle": "2025-04-15T10:02:33.974211Z",
          "shell.execute_reply.started": "2025-04-15T10:02:33.689871Z",
          "shell.execute_reply": "2025-04-15T10:02:33.973338Z"
        },
        "id": "021Fjov5b75e"
      },
      "outputs": [],
      "execution_count": 44
    },
    {
      "cell_type": "code",
      "source": [
        "for root, _, files in os.walk(dataset_dir):\n",
        "    for file in files:\n",
        "        if not file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
        "            print(f\"⚠️ Found non-image file: {file}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T10:02:33.975771Z",
          "iopub.execute_input": "2025-04-15T10:02:33.975997Z",
          "iopub.status.idle": "2025-04-15T10:02:33.981995Z",
          "shell.execute_reply.started": "2025-04-15T10:02:33.975978Z",
          "shell.execute_reply": "2025-04-15T10:02:33.981312Z"
        },
        "id": "G8o5r3Mab75f"
      },
      "outputs": [],
      "execution_count": 45
    },
    {
      "cell_type": "code",
      "source": [
        "for root, _, files in os.walk(dataset_dir):\n",
        "    for file in files:\n",
        "        file_path = os.path.join(root, file)\n",
        "        if file.lower().endswith(('.png', '.bmp', '.tiff', '.gif', '.webp')):\n",
        "            try:\n",
        "                img = Image.open(file_path).convert('RGB')\n",
        "                new_path = file_path.rsplit(\".\", 1)[0] + \".jpg\"\n",
        "                img.save(new_path, \"JPEG\")\n",
        "                os.remove(file_path)  # Remove original\n",
        "                print(f\"✅ Converted {file} to {new_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Failed to convert {file}: {e}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T10:02:33.982777Z",
          "iopub.execute_input": "2025-04-15T10:02:33.983061Z",
          "iopub.status.idle": "2025-04-15T10:02:33.998806Z",
          "shell.execute_reply.started": "2025-04-15T10:02:33.983039Z",
          "shell.execute_reply": "2025-04-15T10:02:33.997989Z"
        },
        "id": "NpO6G_Qqb75f"
      },
      "outputs": [],
      "execution_count": 46
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = \"/content/sample_data/Dataset\"\n",
        "\n",
        "# Hyper parameters\n",
        "img_size = 300\n",
        "batch_size = 32\n",
        "epochs = 13\n",
        "folds = 4  # Number of cross-validation folds\n",
        "Lr = 0.0001\n",
        "\n",
        "# STEP 1: SPLITTING DATASET (80% Train, 20% Test)\n",
        "all_data_dir = os.listdir(dataset_dir)\n",
        "train_test_dir = \"/content/split_dataset\"\n",
        "train_dir = os.path.join(train_test_dir, \"train\")\n",
        "test_dir = os.path.join(train_test_dir, \"test\")\n",
        "\n",
        "# Create train and test folders\n",
        "if not os.path.exists(train_test_dir):\n",
        "    os.makedirs(train_dir)\n",
        "    os.makedirs(test_dir)\n",
        "\n",
        "    # Loop through classes\n",
        "    for class_name in all_data_dir:\n",
        "        class_path = os.path.join(dataset_dir, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            images = os.listdir(class_path)\n",
        "            train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "            # Create class folders\n",
        "            os.makedirs(os.path.join(train_dir, class_name))\n",
        "            os.makedirs(os.path.join(test_dir, class_name))\n",
        "\n",
        "            # Move images\n",
        "            for img in train_images:\n",
        "                shutil.copy(os.path.join(class_path, img), os.path.join(train_dir, class_name, img))\n",
        "            for img in test_images:\n",
        "                shutil.copy(os.path.join(class_path, img), os.path.join(test_dir, class_name, img))\n",
        "\n",
        "# STEP 2: SPLITTING TRAINING SET (70% Train, 30% Validation)\n",
        "train_valid_dir = \"/content/train_validation_split\"\n",
        "train_subdir = os.path.join(train_valid_dir, \"train\")\n",
        "valid_subdir = os.path.join(train_valid_dir, \"valid\")\n",
        "\n",
        "if not os.path.exists(train_valid_dir):\n",
        "    os.makedirs(train_subdir)\n",
        "    os.makedirs(valid_subdir)\n",
        "\n",
        "    for class_name in os.listdir(train_dir):\n",
        "        class_path = os.path.join(train_dir, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            images = os.listdir(class_path)\n",
        "            train_images, valid_images = train_test_split(images, test_size=0.3, random_state=42)\n",
        "\n",
        "            os.makedirs(os.path.join(train_subdir, class_name))\n",
        "            os.makedirs(os.path.join(valid_subdir, class_name))\n",
        "\n",
        "            for img in train_images:\n",
        "                shutil.copy(os.path.join(class_path, img), os.path.join(train_subdir, class_name, img))\n",
        "            for img in valid_images:\n",
        "                shutil.copy(os.path.join(class_path, img), os.path.join(valid_subdir, class_name, img))\n",
        "\n",
        "# STEP 3: DATA AUGMENTATION & PREPROCESSING\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1.0 / 255,  # Normalize pixel values\n",
        "    rotation_range=30,  # Rotate images up to 30 degrees\n",
        "    width_shift_range=0.2,  # Shift images horizontally\n",
        "    height_shift_range=0.2,  # Shift images vertically\n",
        "    shear_range=0.2,  # Apply shear transformations\n",
        "    zoom_range=0.2,  # Random zooming\n",
        "    horizontal_flip=True,  # Flip images horizontally\n",
        "    brightness_range=[0.8, 1.2],  # Adjust brightness\n",
        "    fill_mode=\"nearest\",  # Fill missing pixels after transformationsrescale=1.0 / 255)\n",
        "                            )\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_subdir, target_size=(img_size, img_size), batch_size=batch_size, class_mode='categorical'\n",
        ")\n",
        "valid_generator = datagen.flow_from_directory(\n",
        "    valid_subdir, target_size=(img_size, img_size), batch_size=batch_size, class_mode='categorical'\n",
        ")\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir, target_size=(img_size, img_size), batch_size=batch_size, class_mode='categorical', shuffle=False\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T10:02:33.999711Z",
          "iopub.execute_input": "2025-04-15T10:02:33.999924Z",
          "iopub.status.idle": "2025-04-15T10:02:34.072459Z",
          "shell.execute_reply.started": "2025-04-15T10:02:33.999906Z",
          "shell.execute_reply": "2025-04-15T10:02:34.071650Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuLTqn7mb75f",
        "outputId": "8351df59-feae-453b-af03-eb54988f9bdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1438 images belonging to 5 classes.\n",
            "Found 618 images belonging to 5 classes.\n",
            "Found 515 images belonging to 5 classes.\n"
          ]
        }
      ],
      "execution_count": 50
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-08T11:32:53.683294Z",
          "iopub.execute_input": "2025-04-08T11:32:53.683610Z",
          "iopub.status.idle": "2025-04-08T11:32:53.692528Z",
          "shell.execute_reply.started": "2025-04-08T11:32:53.683579Z",
          "shell.execute_reply": "2025-04-08T11:32:53.691677Z"
        },
        "id": "BCsWQ-Rzb75f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"bold text\n",
        "# STEP 4: BUILD CNN MODEL\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(256, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# STEP 5: CROSS-VALIDATION\n",
        "\n",
        "for fold in range(folds):\n",
        "    print(f\"\\n🚀 Cross-validation fold {fold + 1}/{folds}...\\n\")\n",
        "    model.fit(train_generator, validation_data=valid_generator, epochs=epochs)\n",
        "\n",
        "# STEP 6: TEST MODEL ON UNSEEN DATA\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"\\n🧪 Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "print(f\"🧪 Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# Define a counter\n",
        "counter = 1\n",
        "filename = f\"/kaggle/working/my_model_{counter}.h5\"\n",
        "\n",
        "# Find the next available number\n",
        "while os.path.exists(filename):\n",
        "    counter += 1\n",
        "    filename =  f\"/kaggle/working/my_model_{counter}_acc{test_acc}.h5\"\n",
        "\n",
        "# Save the model\n",
        "model.save(filename)\n",
        "print(f\"✅ Model saved as: {filename}\")\n",
        "\n",
        "\n",
        "# STEP 7: DISPLAY PREDICTIONS\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get test images and labels\n",
        "test_images, test_labels = next(test_generator)\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Show first 5 images and predictions\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(test_images[i])\n",
        "    plt.title(f\"Predicted: {np.argmax(predictions[i])}\\nActual: {np.argmax(test_labels[i])}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\"\"\""
      ],
      "metadata": {
        "id": "58OqRV9DhgSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inception"
      ],
      "metadata": {
        "id": "yhhtARRIhopt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# STEP 4: LOAD PRETRAINED INCEPTIONV3 MODEL\n",
        "base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size, 3))\n",
        "\n",
        "# Freeze base model layers\n",
        "base_model.trainable = True # This prevents training the pre-trained layers\n",
        "\n",
        "# Add Custom Classification Head\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)  # Replaces Flatten\n",
        "x = Dense(512, activation=\"relu\")(x)\n",
        "x = Dropout(0.4)(x)\n",
        "output_layer = Dense(train_generator.num_classes, activation=\"softmax\")(x)  # Adjusts for your classes\n",
        "\n",
        "# Create Model\n",
        "model = Model(inputs=base_model.input, outputs=output_layer)\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# STEP 5: CROSS-VALIDATION\n",
        "for fold in range(folds):\n",
        "    print(f\"\\n🚀 Cross-validation fold {fold + 1}/{folds}...\\n\")\n",
        "    model.fit(train_generator, validation_data=valid_generator, epochs=epochs)\n",
        "\n",
        "# STEP 6: TEST MODEL ON UNSEEN DATA\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"\\n🧪 Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "print(f\"🧪 Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# Define a counter\n",
        "counter = 1\n",
        "filename = f\"/kaggle/working/my_model_{counter}_acc{test_acc:.4f}.h5\"\n",
        "\n",
        "# Find the next available number\n",
        "while os.path.exists(filename):\n",
        "    counter += 1\n",
        "    filename = f\"/kaggle/working/my_model_{counter}_acc{test_acc:.4f}.h5\"\n",
        "\n",
        "# Save the model\n",
        "model.save(filename)\n",
        "print(f\"✅ Model saved as: {filename}\")\n",
        "\n",
        "output_path = f\"/kaggle/working/{filename}\"\n",
        "shutil.move(filename, output_path)\n",
        "print(f\"✅ Model moved to {output_path}\")\n",
        "\n",
        "# STEP 7: DISPLAY PREDICTIONS\n",
        "test_images, test_labels = next(test_generator)\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Show first 5 images and predictions\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(test_images[i])\n",
        "    plt.title(f\"Predicted: {np.argmax(predictions[i])}\\nActual: {np.argmax(test_labels[i])}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T10:02:34.073324Z",
          "iopub.execute_input": "2025-04-15T10:02:34.073543Z",
          "iopub.status.idle": "2025-04-15T11:50:32.760742Z",
          "shell.execute_reply.started": "2025-04-15T10:02:34.073505Z",
          "shell.execute_reply": "2025-04-15T11:50:32.759429Z"
        },
        "id": "mhXtmLSPb75g"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNet"
      ],
      "metadata": {
        "id": "PFEJtvFGht2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# STEP 4: LOAD PRETRAINED EFFICIENTNETB3 MODEL\n",
        "base_model = EfficientNetB3(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size, 3))\n",
        "\n",
        "# Freeze base model layers\n",
        "base_model.trainable = True  # You can set to False if you want to fine-tune only the top layers initially\n",
        "\n",
        "# Add Custom Classification Head\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output_layer = Dense(train_generator.num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "# Create Model\n",
        "model = Model(inputs=base_model.input, outputs=output_layer)\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=Adam(learning_rate=Lr), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# STEP 5: CROSS-VALIDATION\n",
        "for fold in range(folds):\n",
        "    print(f\"\\n🚀 Cross-validation fold {fold + 1}/{folds}...\\n\")\n",
        "    model.fit(train_generator, validation_data=valid_generator, epochs=epochs)\n",
        "\n",
        "# STEP 6: TEST MODEL ON UNSEEN DATA\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"\\n🧪 Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "print(f\"🧪 Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# Define a counter\n",
        "counter = 1\n",
        "filename = f\"/content/drive/MyDrive/Virtual Operator/Models/EfficientNet_{counter}_acc{test_acc:.4f}.h5\"\n",
        "\n",
        "# Find the next available number\n",
        "while os.path.exists(filename):\n",
        "    counter += 1\n",
        "    filename = f\"/content/drive/MyDrive/Virtual Operator/Models/EfficientNet_{counter}_acc{test_acc:.4f}.h5\"\n",
        "\n",
        "# Save the model\n",
        "model.save(filename)\n",
        "print(f\"✅ Model saved as: {filename}\")\n",
        "\n",
        "output_path = f\"/content/drive/MyDrive/Virtual Operator/Models/{filename}\"\n",
        "shutil.move(filename, output_path)\n",
        "print(f\"✅ Model moved to {output_path}\")\n",
        "\n",
        "# STEP 7: DISPLAY PREDICTIONS\n",
        "test_images, test_labels = next(test_generator)\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Show first 5 images and predictions\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.imshow(test_images[i])\n",
        "    plt.title(f\"Predicted: {np.argmax(predictions[i])}\\nActual: {np.argmax(test_labels[i])}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T11:50:32.761166Z",
          "iopub.status.idle": "2025-04-15T11:50:32.761412Z",
          "shell.execute_reply": "2025-04-15T11:50:32.761311Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5OdIa2Wb75g",
        "outputId": "f1991df0-2fc4-44b3-95ab-136ba6e5ab8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
            "\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "🚀 Cross-validation fold 1/4...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 10s/step - accuracy: 0.5307 - loss: 1.2319 - val_accuracy: 0.1845 - val_loss: 1.6529\n",
            "Epoch 2/13\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 7s/step - accuracy: 0.9354 - loss: 0.2342 - val_accuracy: 0.2136 - val_loss: 1.6426\n",
            "Epoch 3/13\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 7s/step - accuracy: 0.9771 - loss: 0.0859 - val_accuracy: 0.1861 - val_loss: 1.7209\n",
            "Epoch 4/13\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 8s/step - accuracy: 0.9857 - loss: 0.0483 - val_accuracy: 0.2152 - val_loss: 1.7045\n",
            "Epoch 5/13\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 6s/step - accuracy: 0.9925 - loss: 0.0322 - val_accuracy: 0.2460 - val_loss: 1.8175\n",
            "Epoch 6/13\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 6s/step - accuracy: 0.9951 - loss: 0.0175 - val_accuracy: 0.4773 - val_loss: 1.2821\n",
            "Epoch 7/13\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 6s/step - accuracy: 0.9984 - loss: 0.0185 - val_accuracy: 0.5421 - val_loss: 1.1688\n",
            "Epoch 8/13\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 7s/step - accuracy: 0.9951 - loss: 0.0209 - val_accuracy: 0.7718 - val_loss: 0.6484\n",
            "Epoch 9/13\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 6s/step - accuracy: 0.9996 - loss: 0.0073 - val_accuracy: 0.7718 - val_loss: 0.5970\n",
            "Epoch 10/13\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 6s/step - accuracy: 0.9992 - loss: 0.0078 - val_accuracy: 0.6327 - val_loss: 1.1213\n",
            "Epoch 11/13\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 6s/step - accuracy: 0.9984 - loss: 0.0078 - val_accuracy: 0.8592 - val_loss: 0.3441\n",
            "Epoch 12/13\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 6s/step - accuracy: 0.9964 - loss: 0.0115 - val_accuracy: 0.2508 - val_loss: 2.0409\n",
            "Epoch 13/13\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 6s/step - accuracy: 0.9986 - loss: 0.0062 - val_accuracy: 0.8770 - val_loss: 0.3633\n",
            "\n",
            "🚀 Cross-validation fold 2/4...\n",
            "\n",
            "Epoch 1/13\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 6s/step - accuracy: 0.9895 - loss: 0.0212 - val_accuracy: 0.2605 - val_loss: 2.0116\n",
            "Epoch 2/13\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 6s/step - accuracy: 0.9928 - loss: 0.0152 - val_accuracy: 0.3091 - val_loss: 2.0160\n",
            "Epoch 3/13\n",
            "\u001b[1m44/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.9954 - loss: 0.0123"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 🔹 Load your trained model (adjust path as needed)\n",
        "model_path = \"/kaggle/working/my_model_1_acc0.9962.h5\"  # Update with your model name\n",
        "model = load_model(model_path)\n",
        "\n",
        "# 🔹 Load and preprocess the image\n",
        "img_path = \"/kaggle/working/Dataset/Hero/IMG_20250318_011706_1.jpg\"  # Replace with your image path\n",
        "img = image.load_img(img_path, target_size=(img_size, img_size))  # Resize to match model input\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array = img_array / 255.0  # Normalize\n",
        "\n",
        "# 🔹 Predict\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "# 🔹 Get class labels from generator\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "predicted_label = class_labels[predicted_class]\n",
        "\n",
        "# 🔹 Display\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Predicted: {predicted_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T11:50:32.762183Z",
          "iopub.status.idle": "2025-04-15T11:50:32.762514Z",
          "shell.execute_reply": "2025-04-15T11:50:32.762356Z"
        },
        "id": "qtE50Aafb75g"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}